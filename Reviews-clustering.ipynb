{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Reviews-clustering.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNXiplPzmxlsIBgxY67fkKW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import string\n","from string import digits\n","import numpy as np\n","import nltk\n","import pandas as pd\n","import re\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","from nltk.stem import WordNetLemmatizer\n","from sklearn.decomposition import TruncatedSVD\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.cluster import DBSCAN\n","from nltk.tokenize import RegexpTokenizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.decomposition import LatentDirichletAllocation \n","import sys\n","import os\n","from google.colab import drive\n","drive.mount('/drive', force_remount=True)\n","\n","# DOWNLOADS\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","nltk.download(\"stopwords\")\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","sw = stopwords.words(\"english\")\n","\n","########## CONFIG ##########\n","notebook_drive_path = '/drive/MyDrive/Colab Notebooks/Hermes_reviews_experiment/'\n","MAX_DF = 1.0\n","MIN_DF = 1\n","APPLY_LSA = False # (Latent semantic analysis) / SVD (Singular value decomposition) in text analysis context\n","LSA_N_COMPONENTS = 400\n","EPS = 0.8\n","MIN_SAMPLES = 2\n","TARGET_TOPICS = 3\n","########## CONFIG ##########"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YUWLMlAg_LVf","executionInfo":{"status":"ok","timestamp":1654842450839,"user_tz":-120,"elapsed":27807,"user":{"displayName":"Jonathan Simeone","userId":"01736008147765826623"}},"outputId":"b9eb0e3d-3ee9-46b5-e45a-adff7303993f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /drive\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/omw-1.4.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]}]},{"cell_type":"code","source":["lemmatizer = WordNetLemmatizer()\n","stemmer = PorterStemmer()\n","\n","def filter_nouns(sentence):\n","  is_noun = lambda pos: pos[:2] == 'NN'\n","  tokenized = nltk.word_tokenize(sentence)\n","  nouns = [word for (word, pos) in nltk.pos_tag(tokenized) if(pos[:2] == 'NN')]\n","  return nouns\n","\n","def clean(sentence):\n","    only_nouns = filter_nouns(sentence)\n","    lower_case = ' '.join(only_nouns).lower()\n","    no_punctuation = re.sub(r\"[,.'’‘\\\"“”:;/*()%@#?§£Є°#\\\\^\\+\\-ç!&$]+\\ *\", \" \", lower_case)\n","    no_escape = re.sub(r'(\\r\\n|\\n|\\r|\\t)', ' ', no_punctuation)\n","    no_urls = re.sub(r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)', ' ', no_escape)\n","    no_emoji = re.sub(r\"[\"u\"\\U0001F600-\\U0001F64F\"\n","                  u\"\\U0001F300-\\U0001F5FF\"  \n","                  u\"\\U0001F680-\\U0001F6FF\"  \n","                  u\"\\U0001F1E0-\\U0001F1FF\" \n","                  u\"\\U00002702-\\U000027B0\"\n","                  u\"\\U000024C2-\\U0001F251\"\n","                  \"]+\", \" \", no_urls, flags=re.UNICODE)\n","    only_alpha = re.sub(\"[^a-z]+\", \" \", no_emoji)\n","    no_digits = only_alpha.translate(str.maketrans('', '', digits))\n","    return no_digits\n","\n","def tokenize(sentence):\n","    cleaned = clean(sentence)\n","    lemmatized = [lemmatizer.lemmatize(word) for word in str(cleaned).split() if word not in sw]\n","    stemmed = [stemmer.stem(word) for word in lemmatized]\n","    return stemmed\n","\n","print('1) Loading CSV...')\n","df = pd.read_csv(notebook_drive_path + 'test.csv', index_col=0)\n","\n","print('2) Vectorizing...')\n","cv = CountVectorizer(min_df=MIN_DF, max_df=MAX_DF, analyzer=tokenize)\n","x_cv = cv.fit_transform(df['Review']).toarray()\n","\n","print('\\nTokens:')\n","print(cv.get_feature_names_out())\n","print('\\n')\n","\n","print('3) Generating TF-IDF matrix...\\n')\n","tfidf_converter = TfidfTransformer()\n","x_tf_matrix = tfidf_converter.fit_transform(x_cv).toarray()\n","\n","print('Vocabulary Size : ', len(cv.get_feature_names_out()))\n","print('Shape of Matrix : ', x_tf_matrix.shape)\n","\n","data_matrix = x_tf_matrix\n","if APPLY_LSA:\n","    print('\\nApplying LSA/SVD analysis...')\n","    svd = TruncatedSVD(n_components=LSA_N_COMPONENTS)\n","    svd_matrix = svd.fit_transform(x_tf_matrix)\n","    data_matrix = svd_matrix\n","    print('LSA output shape:', svd_matrix.shape)\n","\n","print('\\n4) Clustering...')\n","\n","clusterer = DBSCAN(eps=EPS, min_samples=MIN_SAMPLES, metric='cosine', n_jobs=-1)\n","\n","clusterer_name = 'DBSCAN'\n","print('\\nClusterer: ' + clusterer_name)\n","result = clusterer.fit_predict(data_matrix)\n","\n","print('\\n5)Generating clusters dataframe...')\n","clusters_df = pd.DataFrame(columns=['Review', 'Cluster'], data=zip(df['Review'], result))\n","print('\\n')\n","print(clusters_df['Cluster'].value_counts())\n","print('\\n')\n","print('6) Saving clusters csv...')\n","clusters_df.to_csv(notebook_drive_path + clusterer_name + '_GREENWICH_clusters.csv')\n","\n","print('\\n7) Analizing clusters for topics extraction...')\n","\n","clusters = clusters_df['Cluster'].unique()\n","print('\\nNum of clusters (with possible noise cluster = -1):', len(clusters))\n","print('Clusters labels: ', clusters)\n","print('\\n')\n","\n","print('CLUSTERS:')\n","\n","clusters_df['Cluster_topics'] = None\n","\n","clusters_topics = dict()\n","\n","for cluster in clusters:\n","  topics = []\n","\n","  print('---------------------')\n","  print('Cluster ' + (str(cluster) + '\\n' if cluster != -1 else 'NOISY:\\n'))\n","  cluster_reviews = clusters_df.query(\"Cluster == \" + str(cluster))\n","  reviews = cluster_reviews['Review'].tolist()\n","\n","  print('Tokenizing...\\n')\n","  tokenizer = RegexpTokenizer(r'\\w+')\n","  tfidf = TfidfVectorizer(lowercase=True,\n","                        stop_words='english',\n","                        tokenizer = tokenizer.tokenize)\n","\n","  data = tfidf.fit_transform(reviews) \n","  terms = tfidf.get_feature_names_out()\n","  print('\\nOriginal terms')\n","  print(terms)\n","  print('\\nNouns only:')\n","  nouns = filter_nouns(' '.join(terms))\n","  print(nouns)\n","\n","  print('\\nApplying LDA...\\n')\n","  model=LatentDirichletAllocation(n_components=1)\n","  lda_matrix = model.fit_transform(data)\n","  lda_components=model.components_\n","\n","  for index, component in enumerate(lda_components):\n","      zipped = zip(nouns, component)\n","      top_nouns_key=sorted(zipped, key = lambda t: t[1], reverse=True)[:TARGET_TOPICS]\n","      top_nouns_list=list(dict(top_nouns_key).keys())\n","      topics = topics + top_nouns_list\n","     \n","  print(\"\\nTOPICS: \", topics)\n","  clusters_topics[cluster] = topics\n","  print('---------------------')\n","\n","clusters_df['Cluster_topics'] = clusters_df.apply(lambda row: clusters_topics[row['Cluster']], axis = 1)\n","\n","print('\\n8) Saving labeled clusters csv...')\n","clusters_df.to_csv(notebook_drive_path + clusterer_name + '_clusters_LABELED.csv')\n","print('\\n\\nDONE:\\n\\n')\n","print(clusters_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rjxUTcAL4bx_","executionInfo":{"status":"ok","timestamp":1654846177529,"user_tz":-120,"elapsed":908,"user":{"displayName":"Jonathan Simeone","userId":"01736008147765826623"}},"outputId":"2bf803fa-7d19-462c-d07d-93afb0909fd1"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["1) Loading CSV...\n","2) Vectorizing...\n","\n","Tokens:\n","['air' 'famili' 'friend' 'guid' 'lawn' 'mainten' 'monument' 'natur'\n"," 'order' 'outdoor' 'picnic' 'place' 'restaur' 'rude' 'servic' 'staff'\n"," 'toilet' 'view' 'waiter']\n","\n","\n","3) Generating TF-IDF matrix...\n","\n","Vocabulary Size :  19\n","Shape of Matrix :  (11, 19)\n","\n","4) Clustering...\n","\n","Clusterer: DBSCAN\n","\n","5)Generating clusters dataframe...\n","\n","\n","0    5\n","1    4\n","2    2\n","Name: Cluster, dtype: int64\n","\n","\n","6) Saving clusters csv...\n","\n","7) Analizing clusters for topics extraction...\n","\n","Num of clusters (with possible noise cluster = -1): 3\n","Clusters labels:  [0 1 2]\n","\n","\n","CLUSTERS:\n","---------------------\n","Cluster 0\n","\n","Tokenizing...\n","\n","\n","Original terms\n","['air' 'beautiful' 'bring' 'clean' 'definitely' 'eat' 'enjoy' 'family'\n"," 'friends' 'great' 'immerse' 'lawns' 'like' 'nature' 'outdoors' 'perfect'\n"," 'picnic' 'picnicking' 'place' 'really' 'relaxing' 'restaurant'\n"," 'restaurants' 'return' 's' 'soon' 'stunning' 'surrounded' 'vast' 'views']\n","\n","Nouns only:\n","['air', 'family', 'lawns', 'nature', 'outdoors', 'place', 'restaurant', 'restaurants', 'views']\n","\n","Applying LDA...\n","\n","\n","TOPICS:  ['restaurants', 'lawns', 'place']\n","---------------------\n","---------------------\n","Cluster 1\n","\n","Tokenizing...\n","\n","\n","Original terms\n","['bad' 'insulted' 'maintenance' 'order' 'possible' 'rude' 's' 'service'\n"," 'staff' 'toilets' 'waiter' 'work']\n","\n","Nouns only:\n","['maintenance', 'order', 'rude', 'service', 'staff', 'toilets', 'work']\n","\n","Applying LDA...\n","\n","\n","TOPICS:  ['maintenance', 'toilets', 'service']\n","---------------------\n","---------------------\n","Cluster 2\n","\n","Tokenizing...\n","\n","\n","Original terms\n","['cared' 'fantastic' 'friendly' 'guide' 'guides' 'knowledgeable'\n"," 'monument' 'prepared' 'toner']\n","\n","Nouns only:\n","['guides', 'monument', 'toner']\n","\n","Applying LDA...\n","\n","\n","TOPICS:  ['toner', 'guides', 'monument']\n","---------------------\n","\n","8) Saving labeled clusters csv...\n","\n","\n","DONE:\n","\n","\n","                                                                                                                           Review  \\\n","0                          The place is really beautiful, it's full of restaurants and stunning views. I will definitely be back.   \n","1   A perfect place for the family, there are vast lawns for picnicking and relaxing outdoors. The perfect place to enjoy nature.   \n","2                                                              There are no toilets, the staff are rude and a waiter insulted me.   \n","3                                                                            The place is great, surrounded by nature, clean air.   \n","4                                                               In the restaurant you eat very well, I will also bring my friends   \n","5                                                                                    Rude staff, will never go back, bad service.   \n","6                                                                                      Toilets out of order, no maintenance, bad.   \n","7                                                       The monument is well cared for, fantastic, the guides very well prepared.   \n","8                                                                   The guide was very knowledgeable and friendly. We will toner.   \n","9                                                           It's not possible that the toilets will never work, all out of order.   \n","10                                      I would like to return soon to immerse myself in nature and have a picnic with my family.   \n","\n","    Cluster                   Cluster_topics  \n","0         0      [restaurants, lawns, place]  \n","1         0      [restaurants, lawns, place]  \n","2         1  [maintenance, toilets, service]  \n","3         0      [restaurants, lawns, place]  \n","4         0      [restaurants, lawns, place]  \n","5         1  [maintenance, toilets, service]  \n","6         1  [maintenance, toilets, service]  \n","7         2        [toner, guides, monument]  \n","8         2        [toner, guides, monument]  \n","9         1  [maintenance, toilets, service]  \n","10        0      [restaurants, lawns, place]  \n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","pd.set_option('display.max_colwidth', None)\n","df = pd.read_csv(notebook_drive_path + 'DBSCAN_clusters_LABELED.csv', index_col=0)\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":394},"id":"c7rohqFDU0hB","executionInfo":{"status":"ok","timestamp":1654843071257,"user_tz":-120,"elapsed":425,"user":{"displayName":"Jonathan Simeone","userId":"01736008147765826623"}},"outputId":"7664eae6-ba26-48a7-fca6-da24b94e56b0"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                                                                           Review  \\\n","0                          The place is really beautiful, it's full of restaurants and stunning views. I will definitely be back.   \n","1   A perfect place for the family, there are vast lawns for picnicking and relaxing outdoors. The perfect place to enjoy nature.   \n","2                                                              There are no toilets, the staff are rude and a waiter insulted me.   \n","3                                                                            The place is great, surrounded by nature, clean air.   \n","4                                                               In the restaurant you eat very well, I will also bring my friends   \n","5                                                                                    Rude staff, will never go back, bad service.   \n","6                                                                                      Toilets out of order, no maintenance, bad.   \n","7                                                       The monument is well cared for, fantastic, the guides very well prepared.   \n","8                                                                   The guide was very knowledgeable and friendly. We will toner.   \n","9                                                           It's not possible that the toilets will never work, all out of order.   \n","10                                      I would like to return soon to immerse myself in nature and have a picnic with my family.   \n","\n","    Cluster                         Cluster_topics  \n","0         0      ['restaurants', 'lawns', 'place']  \n","1         0      ['restaurants', 'lawns', 'place']  \n","2         1  ['maintenance', 'toilets', 'service']  \n","3         0      ['restaurants', 'lawns', 'place']  \n","4         0      ['restaurants', 'lawns', 'place']  \n","5         1  ['maintenance', 'toilets', 'service']  \n","6         1  ['maintenance', 'toilets', 'service']  \n","7         2        ['toner', 'guides', 'monument']  \n","8         2        ['toner', 'guides', 'monument']  \n","9         1  ['maintenance', 'toilets', 'service']  \n","10        0      ['restaurants', 'lawns', 'place']  "],"text/html":["\n","  <div id=\"df-543e01a6-6ffa-4561-a1af-9965b384b833\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Review</th>\n","      <th>Cluster</th>\n","      <th>Cluster_topics</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>The place is really beautiful, it's full of restaurants and stunning views. I will definitely be back.</td>\n","      <td>0</td>\n","      <td>['restaurants', 'lawns', 'place']</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A perfect place for the family, there are vast lawns for picnicking and relaxing outdoors. The perfect place to enjoy nature.</td>\n","      <td>0</td>\n","      <td>['restaurants', 'lawns', 'place']</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>There are no toilets, the staff are rude and a waiter insulted me.</td>\n","      <td>1</td>\n","      <td>['maintenance', 'toilets', 'service']</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>The place is great, surrounded by nature, clean air.</td>\n","      <td>0</td>\n","      <td>['restaurants', 'lawns', 'place']</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>In the restaurant you eat very well, I will also bring my friends</td>\n","      <td>0</td>\n","      <td>['restaurants', 'lawns', 'place']</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Rude staff, will never go back, bad service.</td>\n","      <td>1</td>\n","      <td>['maintenance', 'toilets', 'service']</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Toilets out of order, no maintenance, bad.</td>\n","      <td>1</td>\n","      <td>['maintenance', 'toilets', 'service']</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>The monument is well cared for, fantastic, the guides very well prepared.</td>\n","      <td>2</td>\n","      <td>['toner', 'guides', 'monument']</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>The guide was very knowledgeable and friendly. We will toner.</td>\n","      <td>2</td>\n","      <td>['toner', 'guides', 'monument']</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>It's not possible that the toilets will never work, all out of order.</td>\n","      <td>1</td>\n","      <td>['maintenance', 'toilets', 'service']</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>I would like to return soon to immerse myself in nature and have a picnic with my family.</td>\n","      <td>0</td>\n","      <td>['restaurants', 'lawns', 'place']</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-543e01a6-6ffa-4561-a1af-9965b384b833')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-543e01a6-6ffa-4561-a1af-9965b384b833 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-543e01a6-6ffa-4561-a1af-9965b384b833');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}]}]}